{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Tutorial: Jax Version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The `LANfactory` package is a light-weight convenience package for training `likelihood approximation networks` (LANs) in torch (or keras), \n",
    "starting from supplied training data.\n",
    "\n",
    "[LANs](https://elifesciences.org/articles/65074), although more general in potential scope of applications, were conceived in the context of sequential sampling modeling\n",
    "to account for cognitive processes giving rise to *choice* and *reaction time* data in *n-alternative forced choice experiments* commonly encountered in the cognitive sciences.\n",
    "\n",
    "In this quick tutorial we will use the [`ssms`](https://github.com/AlexanderFengler/ssm_simulators) package to generate our training data using such a sequential sampling model (SSM). The use of of the `LANfactory` package is in no way bound to utilize this `ssms` package."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Install\n",
    "\n",
    "To install the `ssms` package type,\n",
    "\n",
    "`pip install git+https://github.com/AlexanderFengler/ssm_simulators`\n",
    "\n",
    "To install the `LANfactory` package type,\n",
    "\n",
    "`pip install git+https://github.com/AlexanderFengler/LANfactory`\n",
    "\n",
    "Necessary dependency should be installed automatically in the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssms\n",
    "import lanfactory\n",
    "import os\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = \"ddm\"\n",
    "RUN_SIMS = False\n",
    "DEVICE = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the generator config (for MLP LANs)\n",
    "generator_config = deepcopy(ssms.config.data_generator_config[\"lan\"])\n",
    "# Specify generative model (one from the list of included models mentioned above)\n",
    "generator_config[\"model\"] = MODEL\n",
    "# Specify number of parameter sets to simulate\n",
    "generator_config[\"n_parameter_sets\"] = 256\n",
    "# Specify how many samples a simulation run should entail\n",
    "generator_config[\"n_samples\"] = 2000\n",
    "# Specify folder in which to save generated data\n",
    "generator_config[\"output_folder\"] = \"data/lan_mlp/\"\n",
    "\n",
    "# Make model config dict\n",
    "model_config = ssms.config.model_config[MODEL]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_config[\"output_folder\"] = (\n",
    "    \"data/lan_mlp/\"\n",
    "    + generator_config[\"model\"]\n",
    "    + \"/\"\n",
    "    + str(generator_config[\"n_samples\"])\n",
    "    + \"_\"\n",
    "    + str(generator_config[\"n_training_samples_by_parameter_set\"])\n",
    "    + \"/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_SIMS:\n",
    "    n_datafiles = 20\n",
    "    for i in range(n_datafiles):\n",
    "        print(\"Datafile: \", i)\n",
    "        my_dataset_generator = ssms.dataset_generators.lan_mlp.data_generator(\n",
    "            generator_config=generator_config, model_config=model_config\n",
    "        )\n",
    "        training_data = my_dataset_generator.generate_data_training_uniform(save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "folder_ = \"../data/lan_mlp/\" + MODEL + \"/\"\n",
    "files_ = [folder_ + file_ for file_ in os.listdir(folder_)]\n",
    "\n",
    "my_data = pickle.load(\n",
    "    open(\n",
    "        files_[0],\n",
    "        \"rb\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network config: \n",
      "{'layer_sizes': [100, 100, 100, 1], 'activations': ['tanh', 'tanh', 'tanh', 'linear'], 'train_output_type': 'logprob'}\n",
      "Train config: \n",
      "{'cpu_batch_size': 128, 'gpu_batch_size': 256, 'n_epochs': 5, 'optimizer': 'adam', 'learning_rate': 2e-06, 'lr_scheduler': 'reduce_on_plateau', 'lr_scheduler_params': {}, 'weight_decay': 0.0, 'loss': 'huber', 'save_history': True}\n"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "network_config = deepcopy(lanfactory.config.network_configs.network_config_mlp)\n",
    "network_config[\"layer_sizes\"] = [100, 100, 100, 1]\n",
    "network_config[\"activations\"] = [\"tanh\", \"tanh\", \"tanh\", \"linear\"]\n",
    "\n",
    "print(\"Network config: \")\n",
    "print(network_config)\n",
    "\n",
    "train_config = deepcopy(lanfactory.config.network_configs.train_config_mlp)\n",
    "train_config[\"learning_rate\"] = 0.000002\n",
    "\n",
    "print(\"Train config: \")\n",
    "print(train_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'layer_sizes': [100, 100, 100, 1],\n",
       " 'activations': ['tanh', 'tanh', 'tanh', 'linear'],\n",
       " 'train_output_type': 'logprob'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_config[\"cpu_batch_size\"] = 2048\n",
    "train_config[\"gpu_batch_size\"] = 2048\n",
    "train_config[\"n_epochs\"] = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cpu_batch_size': 2048,\n",
       " 'gpu_batch_size': 2048,\n",
       " 'n_epochs': 20,\n",
       " 'optimizer': 'adam',\n",
       " 'learning_rate': 2e-06,\n",
       " 'lr_scheduler': 'reduce_on_plateau',\n",
       " 'lr_scheduler_params': {},\n",
       " 'weight_decay': 0.0,\n",
       " 'loss': 'huber',\n",
       " 'save_history': True}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_ = \"../data/lan_mlp/\" + MODEL + \"/\"\n",
    "file_list_ = [folder_ + file_ for file_ in os.listdir(folder_)][:3]\n",
    "\n",
    "# Training dataset\n",
    "jax_training_dataset = lanfactory.trainers.DatasetTorch(\n",
    "    file_ids=file_list_,\n",
    "    batch_size=(\n",
    "        train_config[DEVICE + \"_batch_size\"]\n",
    "        if torch.cuda.is_available()\n",
    "        else train_config[DEVICE + \"_batch_size\"]\n",
    "    ),\n",
    "    label_lower_bound=np.log(1e-10),\n",
    "    features_key=\"lan_data\",\n",
    "    label_key=\"lan_labels\",\n",
    "    out_framework=\"jax\",\n",
    ")\n",
    "\n",
    "jax_training_dataloader = torch.utils.data.DataLoader(\n",
    "    jax_training_dataset, shuffle=True, batch_size=None, num_workers=1, pin_memory=True\n",
    ")\n",
    "\n",
    "# Validation dataset\n",
    "jax_validation_dataset = lanfactory.trainers.DatasetTorch(\n",
    "    file_ids=file_list_,\n",
    "    batch_size=(\n",
    "        train_config[DEVICE + \"_batch_size\"]\n",
    "        if torch.cuda.is_available()\n",
    "        else train_config[DEVICE + \"_batch_size\"]\n",
    "    ),\n",
    "    label_lower_bound=np.log(1e-10),\n",
    "    features_key=\"lan_data\",\n",
    "    label_key=\"lan_labels\",\n",
    "    out_framework=\"jax\",\n",
    ")\n",
    "\n",
    "jax_validation_dataloader = torch.utils.data.DataLoader(\n",
    "    jax_validation_dataset,\n",
    "    shuffle=True,\n",
    "    batch_size=None,\n",
    "    num_workers=1,\n",
    "    pin_memory=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.6565,  0.5889,  0.6653,  1.7810,  2.1035,  1.0000],\n",
      "        [ 0.7106,  1.1564,  0.5157,  0.3207,  1.0960,  1.0000],\n",
      "        [ 0.9426,  0.6258,  0.3031,  0.6190,  0.7914,  1.0000],\n",
      "        ...,\n",
      "        [-0.6373,  1.2184,  0.5724,  1.5746,  3.2242, -1.0000],\n",
      "        [-2.3111,  1.3941,  0.8636,  0.4946,  1.3389, -1.0000],\n",
      "        [-2.5116,  0.3034,  0.2683,  0.3998,  0.4072, -1.0000]])\n",
      "tensor([[-0.8507],\n",
      "        [-0.7414],\n",
      "        [-0.0710],\n",
      "        ...,\n",
      "        [-1.5046],\n",
      "        [-0.0316],\n",
      "        [ 2.8727]])\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "for xb, yb in jax_training_dataloader:\n",
    "    print(xb)\n",
    "    print(yb)\n",
    "    cnt += 1\n",
    "    if cnt > 0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD NETWORK\n",
    "jax_net = lanfactory.trainers.JaxMLPFactory(network_config=network_config, train=True)\n",
    "pickle.dump(\n",
    "    network_config,\n",
    "    open(\"../data/jax_models/\" + MODEL + \"/jax_network_config.pickle\", \"wb\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "jax_trainer = lanfactory.trainers.ModelTrainerJaxMLP(\n",
    "    train_config=train_config,\n",
    "    model=jax_net,\n",
    "    train_dl=jax_training_dataloader,\n",
    "    valid_dl=jax_validation_dataloader,\n",
    "    pin_memory=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found folder:  ..\n",
      "Moving on...\n",
      "Found folder:  ../data\n",
      "Moving on...\n",
      "Found folder:  ../data/jax_models\n",
      "Moving on...\n",
      "Found folder:  ../data/jax_models/ddm\n",
      "Moving on...\n",
      "Epoch: 0 of 20\n",
      "Training - Step: 0 of 14646 - Loss: 4.5214987\n",
      "Training - Step: 1000 of 14646 - Loss: 0.21748759\n",
      "Training - Step: 2000 of 14646 - Loss: 0.093032986\n",
      "Training - Step: 3000 of 14646 - Loss: 0.06611438\n",
      "Training - Step: 4000 of 14646 - Loss: 0.060834274\n",
      "Training - Step: 5000 of 14646 - Loss: 0.06890257\n",
      "Training - Step: 6000 of 14646 - Loss: 0.06966375\n",
      "Training - Step: 7000 of 14646 - Loss: 0.07706358\n",
      "Training - Step: 8000 of 14646 - Loss: 0.092329554\n",
      "Training - Step: 9000 of 14646 - Loss: 0.077202246\n",
      "Training - Step: 10000 of 14646 - Loss: 0.10673015\n",
      "Training - Step: 11000 of 14646 - Loss: 0.084473066\n",
      "Training - Step: 12000 of 14646 - Loss: 0.07806848\n",
      "Training - Step: 13000 of 14646 - Loss: 0.077695556\n",
      "Training - Step: 14000 of 14646 - Loss: 0.10682073\n",
      "Epoch 0/20 time: 54.20230793952942s\n",
      "Validation - Step: 0 of 14646 - Loss: 0.09187168\n",
      "Validation - Step: 1000 of 14646 - Loss: 0.082057774\n",
      "Validation - Step: 2000 of 14646 - Loss: 0.09149712\n",
      "Validation - Step: 3000 of 14646 - Loss: 0.083097264\n",
      "Validation - Step: 4000 of 14646 - Loss: 0.08520745\n",
      "Validation - Step: 5000 of 14646 - Loss: 0.07470657\n",
      "Validation - Step: 6000 of 14646 - Loss: 0.102297015\n",
      "Validation - Step: 7000 of 14646 - Loss: 0.1142824\n",
      "Validation - Step: 8000 of 14646 - Loss: 0.058669265\n",
      "Validation - Step: 9000 of 14646 - Loss: 0.10084374\n",
      "Validation - Step: 10000 of 14646 - Loss: 0.08471499\n",
      "Validation - Step: 11000 of 14646 - Loss: 0.09148443\n",
      "Validation - Step: 12000 of 14646 - Loss: 0.08751814\n",
      "Validation - Step: 13000 of 14646 - Loss: 0.08478865\n",
      "Validation - Step: 14000 of 14646 - Loss: 0.08238616\n",
      "Epoch 0/20 time: 23.616851806640625s\n",
      "Epoch: 0 / 20, test_loss: 0.09173708409070969\n",
      "Epoch: 1 of 20\n",
      "Training - Step: 0 of 14646 - Loss: 0.08347707\n",
      "Training - Step: 1000 of 14646 - Loss: 0.108360305\n",
      "Training - Step: 2000 of 14646 - Loss: 0.11283386\n",
      "Training - Step: 3000 of 14646 - Loss: 0.070654735\n",
      "Training - Step: 4000 of 14646 - Loss: 0.083552495\n",
      "Training - Step: 5000 of 14646 - Loss: 0.084760875\n",
      "Training - Step: 6000 of 14646 - Loss: 0.098286614\n",
      "Training - Step: 7000 of 14646 - Loss: 0.07166763\n",
      "Training - Step: 8000 of 14646 - Loss: 0.088647604\n",
      "Training - Step: 9000 of 14646 - Loss: 0.101303\n",
      "Training - Step: 10000 of 14646 - Loss: 0.09071542\n",
      "Training - Step: 11000 of 14646 - Loss: 0.085287616\n",
      "Training - Step: 12000 of 14646 - Loss: 0.073993266\n",
      "Training - Step: 13000 of 14646 - Loss: 0.097036354\n",
      "Training - Step: 14000 of 14646 - Loss: 0.08552022\n",
      "Epoch 1/20 time: 53.59501910209656s\n",
      "Validation - Step: 0 of 14646 - Loss: 0.12967548\n",
      "Validation - Step: 1000 of 14646 - Loss: 0.14885268\n",
      "Validation - Step: 2000 of 14646 - Loss: 0.16699424\n",
      "Validation - Step: 3000 of 14646 - Loss: 0.14004439\n",
      "Validation - Step: 4000 of 14646 - Loss: 0.16931486\n",
      "Validation - Step: 5000 of 14646 - Loss: 0.15726756\n",
      "Validation - Step: 6000 of 14646 - Loss: 0.1317427\n",
      "Validation - Step: 7000 of 14646 - Loss: 0.15952934\n",
      "Validation - Step: 8000 of 14646 - Loss: 0.21158296\n",
      "Validation - Step: 9000 of 14646 - Loss: 0.14986216\n",
      "Validation - Step: 10000 of 14646 - Loss: 0.17461711\n",
      "Validation - Step: 11000 of 14646 - Loss: 0.13809845\n",
      "Validation - Step: 12000 of 14646 - Loss: 0.13882366\n",
      "Validation - Step: 13000 of 14646 - Loss: 0.16612366\n",
      "Validation - Step: 14000 of 14646 - Loss: 0.18538949\n",
      "Epoch 1/20 time: 26.066051959991455s\n",
      "Epoch: 1 / 20, test_loss: 0.15651874244213104\n",
      "Epoch: 2 of 20\n",
      "Training - Step: 0 of 14646 - Loss: 0.2004195\n",
      "Training - Step: 1000 of 14646 - Loss: 0.10899347\n",
      "Training - Step: 2000 of 14646 - Loss: 0.07728404\n",
      "Training - Step: 3000 of 14646 - Loss: 0.08873298\n",
      "Training - Step: 4000 of 14646 - Loss: 0.08103152\n",
      "Training - Step: 5000 of 14646 - Loss: 0.072714105\n",
      "Training - Step: 6000 of 14646 - Loss: 0.107687995\n",
      "Training - Step: 7000 of 14646 - Loss: 0.11070348\n",
      "Training - Step: 8000 of 14646 - Loss: 0.095684275\n",
      "Training - Step: 9000 of 14646 - Loss: 0.07558211\n",
      "Training - Step: 10000 of 14646 - Loss: 0.09069905\n",
      "Training - Step: 11000 of 14646 - Loss: 0.08875747\n",
      "Training - Step: 12000 of 14646 - Loss: 0.09098069\n",
      "Training - Step: 13000 of 14646 - Loss: 0.08592111\n",
      "Training - Step: 14000 of 14646 - Loss: 0.11306514\n",
      "Epoch 2/20 time: 44.672183990478516s\n",
      "Validation - Step: 0 of 14646 - Loss: 0.14168891\n",
      "Validation - Step: 1000 of 14646 - Loss: 0.124620356\n",
      "Validation - Step: 2000 of 14646 - Loss: 0.1169059\n",
      "Validation - Step: 3000 of 14646 - Loss: 0.1360805\n",
      "Validation - Step: 4000 of 14646 - Loss: 0.09907822\n",
      "Validation - Step: 5000 of 14646 - Loss: 0.13117681\n",
      "Validation - Step: 6000 of 14646 - Loss: 0.11105788\n",
      "Validation - Step: 7000 of 14646 - Loss: 0.12773211\n",
      "Validation - Step: 8000 of 14646 - Loss: 0.1629206\n",
      "Validation - Step: 9000 of 14646 - Loss: 0.14006135\n",
      "Validation - Step: 10000 of 14646 - Loss: 0.13823444\n",
      "Validation - Step: 11000 of 14646 - Loss: 0.117395416\n",
      "Validation - Step: 12000 of 14646 - Loss: 0.14455506\n",
      "Validation - Step: 13000 of 14646 - Loss: 0.13608247\n",
      "Validation - Step: 14000 of 14646 - Loss: 0.1292173\n",
      "Epoch 2/20 time: 23.28872585296631s\n",
      "Epoch: 2 / 20, test_loss: 0.13692989945411682\n",
      "Epoch: 3 of 20\n",
      "Training - Step: 0 of 14646 - Loss: 0.13580716\n",
      "Training - Step: 1000 of 14646 - Loss: 0.08336111\n",
      "Training - Step: 2000 of 14646 - Loss: 0.12801893\n",
      "Training - Step: 3000 of 14646 - Loss: 0.09591893\n",
      "Training - Step: 4000 of 14646 - Loss: 0.07103171\n",
      "Training - Step: 5000 of 14646 - Loss: 0.11178838\n",
      "Training - Step: 6000 of 14646 - Loss: 0.088521674\n",
      "Training - Step: 7000 of 14646 - Loss: 0.080007955\n",
      "Training - Step: 8000 of 14646 - Loss: 0.09147893\n",
      "Training - Step: 9000 of 14646 - Loss: 0.06396775\n",
      "Training - Step: 10000 of 14646 - Loss: 0.10881589\n",
      "Training - Step: 11000 of 14646 - Loss: 0.083703816\n",
      "Training - Step: 12000 of 14646 - Loss: 0.07249123\n",
      "Training - Step: 13000 of 14646 - Loss: 0.08631551\n",
      "Training - Step: 14000 of 14646 - Loss: 0.08498445\n",
      "Epoch 3/20 time: 44.117599964141846s\n",
      "Validation - Step: 0 of 14646 - Loss: 0.09005754\n",
      "Validation - Step: 1000 of 14646 - Loss: 0.097876534\n",
      "Validation - Step: 2000 of 14646 - Loss: 0.076060705\n",
      "Validation - Step: 3000 of 14646 - Loss: 0.0902033\n",
      "Validation - Step: 4000 of 14646 - Loss: 0.07989739\n",
      "Validation - Step: 5000 of 14646 - Loss: 0.0977259\n",
      "Validation - Step: 6000 of 14646 - Loss: 0.08879918\n",
      "Validation - Step: 7000 of 14646 - Loss: 0.09719833\n",
      "Validation - Step: 8000 of 14646 - Loss: 0.09300491\n",
      "Validation - Step: 9000 of 14646 - Loss: 0.08713879\n",
      "Validation - Step: 10000 of 14646 - Loss: 0.08578699\n",
      "Validation - Step: 11000 of 14646 - Loss: 0.07241288\n",
      "Validation - Step: 12000 of 14646 - Loss: 0.10267687\n",
      "Validation - Step: 13000 of 14646 - Loss: 0.10637848\n",
      "Validation - Step: 14000 of 14646 - Loss: 0.08603764\n",
      "Epoch 3/20 time: 23.2341947555542s\n",
      "Epoch: 3 / 20, test_loss: 0.0927044227719307\n",
      "Epoch: 4 of 20\n",
      "Training - Step: 0 of 14646 - Loss: 0.09229797\n",
      "Training - Step: 1000 of 14646 - Loss: 0.08280085\n",
      "Training - Step: 2000 of 14646 - Loss: 0.099019065\n",
      "Training - Step: 3000 of 14646 - Loss: 0.08332342\n",
      "Training - Step: 4000 of 14646 - Loss: 0.11557163\n",
      "Training - Step: 5000 of 14646 - Loss: 0.10102908\n",
      "Training - Step: 6000 of 14646 - Loss: 0.11897878\n",
      "Training - Step: 7000 of 14646 - Loss: 0.077724025\n",
      "Training - Step: 8000 of 14646 - Loss: 0.09272201\n",
      "Training - Step: 9000 of 14646 - Loss: 0.107841715\n",
      "Training - Step: 10000 of 14646 - Loss: 0.090901665\n",
      "Training - Step: 11000 of 14646 - Loss: 0.0862543\n",
      "Training - Step: 12000 of 14646 - Loss: 0.10237334\n",
      "Training - Step: 13000 of 14646 - Loss: 0.07343099\n",
      "Training - Step: 14000 of 14646 - Loss: 0.10069242\n",
      "Epoch 4/20 time: 48.45692706108093s\n",
      "Validation - Step: 0 of 14646 - Loss: 0.10653162\n",
      "Validation - Step: 1000 of 14646 - Loss: 0.10068864\n",
      "Validation - Step: 2000 of 14646 - Loss: 0.10386972\n",
      "Validation - Step: 3000 of 14646 - Loss: 0.11572726\n",
      "Validation - Step: 4000 of 14646 - Loss: 0.11539364\n",
      "Validation - Step: 5000 of 14646 - Loss: 0.11876249\n",
      "Validation - Step: 6000 of 14646 - Loss: 0.092591025\n",
      "Validation - Step: 7000 of 14646 - Loss: 0.09859748\n",
      "Validation - Step: 8000 of 14646 - Loss: 0.11187804\n",
      "Validation - Step: 9000 of 14646 - Loss: 0.09962353\n",
      "Validation - Step: 10000 of 14646 - Loss: 0.089704484\n",
      "Validation - Step: 11000 of 14646 - Loss: 0.11123429\n",
      "Validation - Step: 12000 of 14646 - Loss: 0.10261668\n",
      "Validation - Step: 13000 of 14646 - Loss: 0.09986712\n",
      "Validation - Step: 14000 of 14646 - Loss: 0.12849095\n",
      "Epoch 4/20 time: 23.614118099212646s\n",
      "Epoch: 4 / 20, test_loss: 0.10601694136857986\n",
      "Epoch: 5 of 20\n",
      "Training - Step: 0 of 14646 - Loss: 0.10850613\n",
      "Training - Step: 1000 of 14646 - Loss: 0.08778313\n",
      "Training - Step: 2000 of 14646 - Loss: 0.07301871\n",
      "Training - Step: 3000 of 14646 - Loss: 0.07499206\n",
      "Training - Step: 4000 of 14646 - Loss: 0.079880744\n",
      "Training - Step: 5000 of 14646 - Loss: 0.08895576\n",
      "Training - Step: 6000 of 14646 - Loss: 0.09878382\n",
      "Training - Step: 7000 of 14646 - Loss: 0.08848046\n",
      "Training - Step: 8000 of 14646 - Loss: 0.079346925\n",
      "Training - Step: 9000 of 14646 - Loss: 0.09869519\n",
      "Training - Step: 10000 of 14646 - Loss: 0.08819844\n",
      "Training - Step: 11000 of 14646 - Loss: 0.10956173\n",
      "Training - Step: 12000 of 14646 - Loss: 0.10346508\n",
      "Training - Step: 13000 of 14646 - Loss: 0.06769349\n",
      "Training - Step: 14000 of 14646 - Loss: 0.109163105\n",
      "Epoch 5/20 time: 51.50389289855957s\n",
      "Validation - Step: 0 of 14646 - Loss: 0.08567913\n",
      "Validation - Step: 1000 of 14646 - Loss: 0.07484421\n",
      "Validation - Step: 2000 of 14646 - Loss: 0.08917777\n",
      "Validation - Step: 3000 of 14646 - Loss: 0.09133488\n",
      "Validation - Step: 4000 of 14646 - Loss: 0.09315367\n",
      "Validation - Step: 5000 of 14646 - Loss: 0.0918681\n",
      "Validation - Step: 6000 of 14646 - Loss: 0.09570733\n",
      "Validation - Step: 7000 of 14646 - Loss: 0.07615656\n",
      "Validation - Step: 8000 of 14646 - Loss: 0.09799516\n",
      "Validation - Step: 9000 of 14646 - Loss: 0.080825165\n",
      "Validation - Step: 10000 of 14646 - Loss: 0.08141769\n",
      "Validation - Step: 11000 of 14646 - Loss: 0.09909807\n",
      "Validation - Step: 12000 of 14646 - Loss: 0.08101839\n",
      "Validation - Step: 13000 of 14646 - Loss: 0.11583821\n",
      "Validation - Step: 14000 of 14646 - Loss: 0.095914006\n",
      "Epoch 5/20 time: 23.385109186172485s\n",
      "Epoch: 5 / 20, test_loss: 0.0863947942852974\n",
      "Epoch: 6 of 20\n",
      "Training - Step: 0 of 14646 - Loss: 0.077175066\n",
      "Training - Step: 1000 of 14646 - Loss: 0.0840203\n",
      "Training - Step: 2000 of 14646 - Loss: 0.07890865\n",
      "Training - Step: 3000 of 14646 - Loss: 0.084335804\n",
      "Training - Step: 4000 of 14646 - Loss: 0.08841969\n",
      "Training - Step: 5000 of 14646 - Loss: 0.09580971\n",
      "Training - Step: 6000 of 14646 - Loss: 0.090682924\n",
      "Training - Step: 7000 of 14646 - Loss: 0.10981654\n",
      "Training - Step: 8000 of 14646 - Loss: 0.08067798\n",
      "Training - Step: 9000 of 14646 - Loss: 0.0942862\n",
      "Training - Step: 10000 of 14646 - Loss: 0.08035685\n",
      "Training - Step: 11000 of 14646 - Loss: 0.078104496\n",
      "Training - Step: 12000 of 14646 - Loss: 0.08981634\n",
      "Training - Step: 13000 of 14646 - Loss: 0.08380946\n",
      "Training - Step: 14000 of 14646 - Loss: 0.082835406\n",
      "Epoch 6/20 time: 45.68016695976257s\n",
      "Validation - Step: 0 of 14646 - Loss: 0.10276818\n",
      "Validation - Step: 1000 of 14646 - Loss: 0.06614443\n",
      "Validation - Step: 2000 of 14646 - Loss: 0.07114384\n",
      "Validation - Step: 3000 of 14646 - Loss: 0.10298829\n",
      "Validation - Step: 4000 of 14646 - Loss: 0.07671536\n",
      "Validation - Step: 5000 of 14646 - Loss: 0.077450916\n",
      "Validation - Step: 6000 of 14646 - Loss: 0.064355746\n",
      "Validation - Step: 7000 of 14646 - Loss: 0.06933825\n",
      "Validation - Step: 8000 of 14646 - Loss: 0.10760656\n",
      "Validation - Step: 9000 of 14646 - Loss: 0.107290894\n",
      "Validation - Step: 10000 of 14646 - Loss: 0.099637225\n",
      "Validation - Step: 11000 of 14646 - Loss: 0.07510857\n",
      "Validation - Step: 12000 of 14646 - Loss: 0.07426647\n",
      "Validation - Step: 13000 of 14646 - Loss: 0.098296314\n",
      "Validation - Step: 14000 of 14646 - Loss: 0.08304219\n",
      "Epoch 6/20 time: 24.165618181228638s\n",
      "Epoch: 6 / 20, test_loss: 0.08062706887722015\n",
      "Epoch: 7 of 20\n",
      "Training - Step: 0 of 14646 - Loss: 0.07783876\n",
      "Training - Step: 1000 of 14646 - Loss: 0.10604235\n",
      "Training - Step: 2000 of 14646 - Loss: 0.08355908\n",
      "Training - Step: 3000 of 14646 - Loss: 0.056895338\n",
      "Training - Step: 4000 of 14646 - Loss: 0.103951514\n",
      "Training - Step: 5000 of 14646 - Loss: 0.086119\n",
      "Training - Step: 6000 of 14646 - Loss: 0.07078935\n",
      "Training - Step: 7000 of 14646 - Loss: 0.083945744\n",
      "Training - Step: 8000 of 14646 - Loss: 0.078182384\n",
      "Training - Step: 9000 of 14646 - Loss: 0.061549224\n",
      "Training - Step: 10000 of 14646 - Loss: 0.07516081\n",
      "Training - Step: 11000 of 14646 - Loss: 0.053185947\n",
      "Training - Step: 12000 of 14646 - Loss: 0.09003869\n",
      "Training - Step: 13000 of 14646 - Loss: 0.0814642\n",
      "Training - Step: 14000 of 14646 - Loss: 0.07987018\n",
      "Epoch 7/20 time: 48.126819133758545s\n",
      "Validation - Step: 0 of 14646 - Loss: 0.080023035\n",
      "Validation - Step: 1000 of 14646 - Loss: 0.12457367\n",
      "Validation - Step: 2000 of 14646 - Loss: 0.10877683\n",
      "Validation - Step: 3000 of 14646 - Loss: 0.09833974\n",
      "Validation - Step: 4000 of 14646 - Loss: 0.09269141\n",
      "Validation - Step: 5000 of 14646 - Loss: 0.118410714\n",
      "Validation - Step: 6000 of 14646 - Loss: 0.11344724\n",
      "Validation - Step: 7000 of 14646 - Loss: 0.11625176\n",
      "Validation - Step: 8000 of 14646 - Loss: 0.09299643\n",
      "Validation - Step: 9000 of 14646 - Loss: 0.09847796\n",
      "Validation - Step: 10000 of 14646 - Loss: 0.09513043\n",
      "Validation - Step: 11000 of 14646 - Loss: 0.10926796\n",
      "Validation - Step: 12000 of 14646 - Loss: 0.110324286\n",
      "Validation - Step: 13000 of 14646 - Loss: 0.12507969\n",
      "Validation - Step: 14000 of 14646 - Loss: 0.08394703\n",
      "Epoch 7/20 time: 23.516163110733032s\n",
      "Epoch: 7 / 20, test_loss: 0.10455071926116943\n",
      "Epoch: 8 of 20\n",
      "Training - Step: 0 of 14646 - Loss: 0.07571347\n",
      "Training - Step: 1000 of 14646 - Loss: 0.08250033\n",
      "Training - Step: 2000 of 14646 - Loss: 0.07316288\n",
      "Training - Step: 3000 of 14646 - Loss: 0.09064652\n",
      "Training - Step: 4000 of 14646 - Loss: 0.09445168\n",
      "Training - Step: 5000 of 14646 - Loss: 0.059105966\n",
      "Training - Step: 6000 of 14646 - Loss: 0.09544583\n",
      "Training - Step: 7000 of 14646 - Loss: 0.062007982\n",
      "Training - Step: 8000 of 14646 - Loss: 0.07067074\n",
      "Training - Step: 9000 of 14646 - Loss: 0.061032366\n",
      "Training - Step: 10000 of 14646 - Loss: 0.08901115\n",
      "Training - Step: 11000 of 14646 - Loss: 0.09442448\n",
      "Training - Step: 12000 of 14646 - Loss: 0.07470007\n",
      "Training - Step: 13000 of 14646 - Loss: 0.08238708\n",
      "Training - Step: 14000 of 14646 - Loss: 0.07915846\n",
      "Epoch 8/20 time: 46.566442012786865s\n",
      "Validation - Step: 0 of 14646 - Loss: 0.06126755\n",
      "Validation - Step: 1000 of 14646 - Loss: 0.07974753\n",
      "Validation - Step: 2000 of 14646 - Loss: 0.07259891\n",
      "Validation - Step: 3000 of 14646 - Loss: 0.07532933\n",
      "Validation - Step: 4000 of 14646 - Loss: 0.08802761\n",
      "Validation - Step: 5000 of 14646 - Loss: 0.059805587\n",
      "Validation - Step: 6000 of 14646 - Loss: 0.07661023\n",
      "Validation - Step: 7000 of 14646 - Loss: 0.07585633\n",
      "Validation - Step: 8000 of 14646 - Loss: 0.07313677\n",
      "Validation - Step: 9000 of 14646 - Loss: 0.09507485\n",
      "Validation - Step: 10000 of 14646 - Loss: 0.06583746\n",
      "Validation - Step: 11000 of 14646 - Loss: 0.080718294\n",
      "Validation - Step: 12000 of 14646 - Loss: 0.062398784\n",
      "Validation - Step: 13000 of 14646 - Loss: 0.07719098\n",
      "Validation - Step: 14000 of 14646 - Loss: 0.07941611\n",
      "Epoch 8/20 time: 24.374584197998047s\n",
      "Epoch: 8 / 20, test_loss: 0.07508186995983124\n",
      "Epoch: 9 of 20\n",
      "Training - Step: 0 of 14646 - Loss: 0.09308756\n",
      "Training - Step: 1000 of 14646 - Loss: 0.0824724\n",
      "Training - Step: 2000 of 14646 - Loss: 0.08336756\n",
      "Training - Step: 3000 of 14646 - Loss: 0.06992352\n",
      "Training - Step: 4000 of 14646 - Loss: 0.08187918\n",
      "Training - Step: 5000 of 14646 - Loss: 0.083580926\n",
      "Training - Step: 6000 of 14646 - Loss: 0.09334436\n",
      "Training - Step: 7000 of 14646 - Loss: 0.07650606\n",
      "Training - Step: 8000 of 14646 - Loss: 0.092295125\n",
      "Training - Step: 9000 of 14646 - Loss: 0.08912447\n",
      "Training - Step: 10000 of 14646 - Loss: 0.07817134\n",
      "Training - Step: 11000 of 14646 - Loss: 0.08309142\n",
      "Training - Step: 12000 of 14646 - Loss: 0.08293176\n",
      "Training - Step: 13000 of 14646 - Loss: 0.059858162\n",
      "Training - Step: 14000 of 14646 - Loss: 0.07826191\n",
      "Epoch 9/20 time: 46.3416531085968s\n",
      "Validation - Step: 0 of 14646 - Loss: 0.09297093\n",
      "Validation - Step: 1000 of 14646 - Loss: 0.06967506\n",
      "Validation - Step: 2000 of 14646 - Loss: 0.065244585\n",
      "Validation - Step: 3000 of 14646 - Loss: 0.06477684\n",
      "Validation - Step: 4000 of 14646 - Loss: 0.06271107\n",
      "Validation - Step: 5000 of 14646 - Loss: 0.072244905\n",
      "Validation - Step: 6000 of 14646 - Loss: 0.088002905\n",
      "Validation - Step: 7000 of 14646 - Loss: 0.06219223\n",
      "Validation - Step: 8000 of 14646 - Loss: 0.08455178\n",
      "Validation - Step: 9000 of 14646 - Loss: 0.07170108\n",
      "Validation - Step: 10000 of 14646 - Loss: 0.077473015\n",
      "Validation - Step: 11000 of 14646 - Loss: 0.072025776\n",
      "Validation - Step: 12000 of 14646 - Loss: 0.07674596\n",
      "Validation - Step: 13000 of 14646 - Loss: 0.08346154\n",
      "Validation - Step: 14000 of 14646 - Loss: 0.0764492\n",
      "Epoch 9/20 time: 23.38094997406006s\n",
      "Epoch: 9 / 20, test_loss: 0.07665248960256577\n",
      "Epoch: 10 of 20\n",
      "Training - Step: 0 of 14646 - Loss: 0.08648458\n",
      "Training - Step: 1000 of 14646 - Loss: 0.065197065\n",
      "Training - Step: 2000 of 14646 - Loss: 0.09923719\n",
      "Training - Step: 3000 of 14646 - Loss: 0.075550064\n",
      "Training - Step: 4000 of 14646 - Loss: 0.07149323\n",
      "Training - Step: 5000 of 14646 - Loss: 0.08455111\n",
      "Training - Step: 6000 of 14646 - Loss: 0.058125682\n",
      "Training - Step: 7000 of 14646 - Loss: 0.08181619\n",
      "Training - Step: 8000 of 14646 - Loss: 0.07366596\n",
      "Training - Step: 9000 of 14646 - Loss: 0.07709588\n",
      "Training - Step: 10000 of 14646 - Loss: 0.08151953\n",
      "Training - Step: 11000 of 14646 - Loss: 0.055492397\n",
      "Training - Step: 12000 of 14646 - Loss: 0.09193392\n",
      "Training - Step: 13000 of 14646 - Loss: 0.06745738\n",
      "Training - Step: 14000 of 14646 - Loss: 0.05935363\n",
      "Epoch 10/20 time: 44.96522307395935s\n",
      "Validation - Step: 0 of 14646 - Loss: 0.07327727\n",
      "Validation - Step: 1000 of 14646 - Loss: 0.07806645\n",
      "Validation - Step: 2000 of 14646 - Loss: 0.08697474\n",
      "Validation - Step: 3000 of 14646 - Loss: 0.06506394\n",
      "Validation - Step: 4000 of 14646 - Loss: 0.06974316\n",
      "Validation - Step: 5000 of 14646 - Loss: 0.064418465\n",
      "Validation - Step: 6000 of 14646 - Loss: 0.072117895\n",
      "Validation - Step: 7000 of 14646 - Loss: 0.07005717\n",
      "Validation - Step: 8000 of 14646 - Loss: 0.0812921\n",
      "Validation - Step: 9000 of 14646 - Loss: 0.08538422\n",
      "Validation - Step: 10000 of 14646 - Loss: 0.076788336\n",
      "Validation - Step: 11000 of 14646 - Loss: 0.062000323\n",
      "Validation - Step: 12000 of 14646 - Loss: 0.07255174\n",
      "Validation - Step: 13000 of 14646 - Loss: 0.06920846\n",
      "Validation - Step: 14000 of 14646 - Loss: 0.071147755\n",
      "Epoch 10/20 time: 22.826266050338745s\n",
      "Epoch: 10 / 20, test_loss: 0.07354491949081421\n",
      "Epoch: 11 of 20\n",
      "Training - Step: 0 of 14646 - Loss: 0.07941611\n",
      "Training - Step: 1000 of 14646 - Loss: 0.071970046\n",
      "Training - Step: 2000 of 14646 - Loss: 0.061745822\n",
      "Training - Step: 3000 of 14646 - Loss: 0.05801288\n",
      "Training - Step: 4000 of 14646 - Loss: 0.06043846\n",
      "Training - Step: 5000 of 14646 - Loss: 0.06328245\n",
      "Training - Step: 6000 of 14646 - Loss: 0.06874238\n",
      "Training - Step: 7000 of 14646 - Loss: 0.08640907\n",
      "Training - Step: 8000 of 14646 - Loss: 0.050666686\n",
      "Training - Step: 9000 of 14646 - Loss: 0.057211857\n",
      "Training - Step: 10000 of 14646 - Loss: 0.07818926\n",
      "Training - Step: 11000 of 14646 - Loss: 0.05966445\n",
      "Training - Step: 12000 of 14646 - Loss: 0.079771616\n",
      "Training - Step: 13000 of 14646 - Loss: 0.06665942\n",
      "Training - Step: 14000 of 14646 - Loss: 0.07277078\n",
      "Epoch 11/20 time: 45.084534645080566s\n",
      "Validation - Step: 0 of 14646 - Loss: 0.06269319\n",
      "Validation - Step: 1000 of 14646 - Loss: 0.0923461\n",
      "Validation - Step: 2000 of 14646 - Loss: 0.08527728\n",
      "Validation - Step: 3000 of 14646 - Loss: 0.070285186\n",
      "Validation - Step: 4000 of 14646 - Loss: 0.07611868\n",
      "Validation - Step: 5000 of 14646 - Loss: 0.053299706\n",
      "Validation - Step: 6000 of 14646 - Loss: 0.07625851\n",
      "Validation - Step: 7000 of 14646 - Loss: 0.0736763\n",
      "Validation - Step: 8000 of 14646 - Loss: 0.07161069\n",
      "Validation - Step: 9000 of 14646 - Loss: 0.06114544\n",
      "Validation - Step: 10000 of 14646 - Loss: 0.07613982\n",
      "Validation - Step: 11000 of 14646 - Loss: 0.055803694\n",
      "Validation - Step: 12000 of 14646 - Loss: 0.07937407\n",
      "Validation - Step: 13000 of 14646 - Loss: 0.07387236\n",
      "Validation - Step: 14000 of 14646 - Loss: 0.05779572\n",
      "Epoch 11/20 time: 23.058305025100708s\n",
      "Epoch: 11 / 20, test_loss: 0.0683840662240982\n",
      "Epoch: 12 of 20\n",
      "Training - Step: 0 of 14646 - Loss: 0.069396466\n",
      "Training - Step: 1000 of 14646 - Loss: 0.06976159\n",
      "Training - Step: 2000 of 14646 - Loss: 0.06378521\n",
      "Training - Step: 3000 of 14646 - Loss: 0.06745066\n",
      "Training - Step: 4000 of 14646 - Loss: 0.07839683\n",
      "Training - Step: 5000 of 14646 - Loss: 0.056658402\n",
      "Training - Step: 6000 of 14646 - Loss: 0.079051904\n",
      "Training - Step: 7000 of 14646 - Loss: 0.07021257\n",
      "Training - Step: 8000 of 14646 - Loss: 0.07928485\n",
      "Training - Step: 9000 of 14646 - Loss: 0.04879287\n",
      "Training - Step: 10000 of 14646 - Loss: 0.05501125\n",
      "Training - Step: 11000 of 14646 - Loss: 0.07190329\n",
      "Training - Step: 12000 of 14646 - Loss: 0.058429405\n",
      "Training - Step: 13000 of 14646 - Loss: 0.08217546\n",
      "Training - Step: 14000 of 14646 - Loss: 0.073768884\n",
      "Epoch 12/20 time: 46.42501902580261s\n",
      "Validation - Step: 0 of 14646 - Loss: 0.089406006\n",
      "Validation - Step: 1000 of 14646 - Loss: 0.06006189\n",
      "Validation - Step: 2000 of 14646 - Loss: 0.06108879\n",
      "Validation - Step: 3000 of 14646 - Loss: 0.06253153\n",
      "Validation - Step: 4000 of 14646 - Loss: 0.06383245\n",
      "Validation - Step: 5000 of 14646 - Loss: 0.07828776\n",
      "Validation - Step: 6000 of 14646 - Loss: 0.073684394\n",
      "Validation - Step: 7000 of 14646 - Loss: 0.058369443\n",
      "Validation - Step: 8000 of 14646 - Loss: 0.058502406\n",
      "Validation - Step: 9000 of 14646 - Loss: 0.07088567\n",
      "Validation - Step: 10000 of 14646 - Loss: 0.073794834\n",
      "Validation - Step: 11000 of 14646 - Loss: 0.07446936\n",
      "Validation - Step: 12000 of 14646 - Loss: 0.06701778\n",
      "Validation - Step: 13000 of 14646 - Loss: 0.06579744\n",
      "Validation - Step: 14000 of 14646 - Loss: 0.06870524\n",
      "Epoch 12/20 time: 22.986857891082764s\n",
      "Epoch: 12 / 20, test_loss: 0.06749078631401062\n",
      "Epoch: 13 of 20\n",
      "Training - Step: 0 of 14646 - Loss: 0.055524223\n",
      "Training - Step: 1000 of 14646 - Loss: 0.0565028\n",
      "Training - Step: 2000 of 14646 - Loss: 0.08561859\n",
      "Training - Step: 3000 of 14646 - Loss: 0.059489597\n",
      "Training - Step: 4000 of 14646 - Loss: 0.059532404\n",
      "Training - Step: 5000 of 14646 - Loss: 0.06737917\n",
      "Training - Step: 6000 of 14646 - Loss: 0.07406294\n",
      "Training - Step: 7000 of 14646 - Loss: 0.07912908\n",
      "Training - Step: 8000 of 14646 - Loss: 0.069793716\n",
      "Training - Step: 9000 of 14646 - Loss: 0.06859936\n",
      "Training - Step: 10000 of 14646 - Loss: 0.04969933\n",
      "Training - Step: 11000 of 14646 - Loss: 0.058756307\n",
      "Training - Step: 12000 of 14646 - Loss: 0.060999084\n",
      "Training - Step: 13000 of 14646 - Loss: 0.062497195\n",
      "Training - Step: 14000 of 14646 - Loss: 0.05937194\n",
      "Epoch 13/20 time: 45.24712324142456s\n",
      "Validation - Step: 0 of 14646 - Loss: 0.05802446\n",
      "Validation - Step: 1000 of 14646 - Loss: 0.08123079\n",
      "Validation - Step: 2000 of 14646 - Loss: 0.07206334\n",
      "Validation - Step: 3000 of 14646 - Loss: 0.07435252\n",
      "Validation - Step: 4000 of 14646 - Loss: 0.0680824\n",
      "Validation - Step: 5000 of 14646 - Loss: 0.06278528\n",
      "Validation - Step: 6000 of 14646 - Loss: 0.058646925\n",
      "Validation - Step: 7000 of 14646 - Loss: 0.0639552\n",
      "Validation - Step: 8000 of 14646 - Loss: 0.06801504\n",
      "Validation - Step: 9000 of 14646 - Loss: 0.07004261\n",
      "Validation - Step: 10000 of 14646 - Loss: 0.09209624\n",
      "Validation - Step: 11000 of 14646 - Loss: 0.057599906\n",
      "Validation - Step: 12000 of 14646 - Loss: 0.07407912\n",
      "Validation - Step: 13000 of 14646 - Loss: 0.06274778\n",
      "Validation - Step: 14000 of 14646 - Loss: 0.051161878\n",
      "Epoch 13/20 time: 23.41210412979126s\n",
      "Epoch: 13 / 20, test_loss: 0.06717845797538757\n",
      "Epoch: 14 of 20\n",
      "Training - Step: 0 of 14646 - Loss: 0.073669285\n",
      "Training - Step: 1000 of 14646 - Loss: 0.05940414\n",
      "Training - Step: 2000 of 14646 - Loss: 0.09662055\n",
      "Training - Step: 3000 of 14646 - Loss: 0.06553097\n",
      "Training - Step: 4000 of 14646 - Loss: 0.060390376\n",
      "Training - Step: 5000 of 14646 - Loss: 0.050999135\n",
      "Training - Step: 6000 of 14646 - Loss: 0.051039353\n",
      "Training - Step: 7000 of 14646 - Loss: 0.05782035\n",
      "Training - Step: 8000 of 14646 - Loss: 0.063219264\n",
      "Training - Step: 9000 of 14646 - Loss: 0.0690466\n",
      "Training - Step: 10000 of 14646 - Loss: 0.06351272\n",
      "Training - Step: 11000 of 14646 - Loss: 0.07671617\n",
      "Training - Step: 12000 of 14646 - Loss: 0.05898655\n",
      "Training - Step: 13000 of 14646 - Loss: 0.07641819\n",
      "Training - Step: 14000 of 14646 - Loss: 0.05350178\n",
      "Epoch 14/20 time: 45.07792782783508s\n",
      "Validation - Step: 0 of 14646 - Loss: 0.057245933\n",
      "Validation - Step: 1000 of 14646 - Loss: 0.089283146\n",
      "Validation - Step: 2000 of 14646 - Loss: 0.0513089\n",
      "Validation - Step: 3000 of 14646 - Loss: 0.07062462\n",
      "Validation - Step: 4000 of 14646 - Loss: 0.046902653\n",
      "Validation - Step: 5000 of 14646 - Loss: 0.072184645\n",
      "Validation - Step: 6000 of 14646 - Loss: 0.07184619\n",
      "Validation - Step: 7000 of 14646 - Loss: 0.075634114\n",
      "Validation - Step: 8000 of 14646 - Loss: 0.058877975\n",
      "Validation - Step: 9000 of 14646 - Loss: 0.055497505\n",
      "Validation - Step: 10000 of 14646 - Loss: 0.064794466\n",
      "Validation - Step: 11000 of 14646 - Loss: 0.051268525\n",
      "Validation - Step: 12000 of 14646 - Loss: 0.055605102\n",
      "Validation - Step: 13000 of 14646 - Loss: 0.062439438\n",
      "Validation - Step: 14000 of 14646 - Loss: 0.07879143\n",
      "Epoch 14/20 time: 22.49425172805786s\n",
      "Epoch: 14 / 20, test_loss: 0.06460357457399368\n",
      "Epoch: 15 of 20\n",
      "Training - Step: 0 of 14646 - Loss: 0.05545774\n",
      "Training - Step: 1000 of 14646 - Loss: 0.061725087\n",
      "Training - Step: 2000 of 14646 - Loss: 0.07931855\n",
      "Training - Step: 3000 of 14646 - Loss: 0.06983648\n",
      "Training - Step: 4000 of 14646 - Loss: 0.07983439\n",
      "Training - Step: 5000 of 14646 - Loss: 0.06790748\n",
      "Training - Step: 6000 of 14646 - Loss: 0.06871298\n",
      "Training - Step: 7000 of 14646 - Loss: 0.069536775\n",
      "Training - Step: 8000 of 14646 - Loss: 0.066931054\n",
      "Training - Step: 9000 of 14646 - Loss: 0.06627773\n",
      "Training - Step: 10000 of 14646 - Loss: 0.06123206\n",
      "Training - Step: 11000 of 14646 - Loss: 0.054193035\n",
      "Training - Step: 12000 of 14646 - Loss: 0.055591397\n",
      "Training - Step: 13000 of 14646 - Loss: 0.039736006\n",
      "Training - Step: 14000 of 14646 - Loss: 0.050641872\n",
      "Epoch 15/20 time: 45.57362413406372s\n",
      "Validation - Step: 0 of 14646 - Loss: 0.048550397\n",
      "Validation - Step: 1000 of 14646 - Loss: 0.050126515\n",
      "Validation - Step: 2000 of 14646 - Loss: 0.05185765\n",
      "Validation - Step: 3000 of 14646 - Loss: 0.05380182\n",
      "Validation - Step: 4000 of 14646 - Loss: 0.059522305\n",
      "Validation - Step: 5000 of 14646 - Loss: 0.05233398\n",
      "Validation - Step: 6000 of 14646 - Loss: 0.07601057\n",
      "Validation - Step: 7000 of 14646 - Loss: 0.06010163\n",
      "Validation - Step: 8000 of 14646 - Loss: 0.05677644\n",
      "Validation - Step: 9000 of 14646 - Loss: 0.06655331\n",
      "Validation - Step: 10000 of 14646 - Loss: 0.04460198\n",
      "Validation - Step: 11000 of 14646 - Loss: 0.08873027\n",
      "Validation - Step: 12000 of 14646 - Loss: 0.0577084\n",
      "Validation - Step: 13000 of 14646 - Loss: 0.044943817\n",
      "Validation - Step: 14000 of 14646 - Loss: 0.08457506\n",
      "Epoch 15/20 time: 25.14597988128662s\n",
      "Epoch: 15 / 20, test_loss: 0.060902658849954605\n",
      "Epoch: 16 of 20\n",
      "Training - Step: 0 of 14646 - Loss: 0.056005225\n",
      "Training - Step: 1000 of 14646 - Loss: 0.049768586\n",
      "Training - Step: 2000 of 14646 - Loss: 0.064523175\n",
      "Training - Step: 3000 of 14646 - Loss: 0.0524295\n",
      "Training - Step: 4000 of 14646 - Loss: 0.061962046\n",
      "Training - Step: 5000 of 14646 - Loss: 0.07686237\n",
      "Training - Step: 6000 of 14646 - Loss: 0.05692176\n",
      "Training - Step: 7000 of 14646 - Loss: 0.06561442\n",
      "Training - Step: 8000 of 14646 - Loss: 0.053502664\n",
      "Training - Step: 9000 of 14646 - Loss: 0.070360444\n",
      "Training - Step: 10000 of 14646 - Loss: 0.07811142\n",
      "Training - Step: 11000 of 14646 - Loss: 0.06371491\n",
      "Training - Step: 12000 of 14646 - Loss: 0.06868358\n",
      "Training - Step: 13000 of 14646 - Loss: 0.08580196\n",
      "Training - Step: 14000 of 14646 - Loss: 0.066707104\n",
      "Epoch 16/20 time: 46.44646501541138s\n",
      "Validation - Step: 0 of 14646 - Loss: 0.06287196\n",
      "Validation - Step: 1000 of 14646 - Loss: 0.0681505\n",
      "Validation - Step: 2000 of 14646 - Loss: 0.07539324\n",
      "Validation - Step: 3000 of 14646 - Loss: 0.07943769\n",
      "Validation - Step: 4000 of 14646 - Loss: 0.049651064\n",
      "Validation - Step: 5000 of 14646 - Loss: 0.079452366\n",
      "Validation - Step: 6000 of 14646 - Loss: 0.064705804\n",
      "Validation - Step: 7000 of 14646 - Loss: 0.053483576\n",
      "Validation - Step: 8000 of 14646 - Loss: 0.056854606\n",
      "Validation - Step: 9000 of 14646 - Loss: 0.05730466\n",
      "Validation - Step: 10000 of 14646 - Loss: 0.056914784\n",
      "Validation - Step: 11000 of 14646 - Loss: 0.06838255\n",
      "Validation - Step: 12000 of 14646 - Loss: 0.07494207\n",
      "Validation - Step: 13000 of 14646 - Loss: 0.054668795\n",
      "Validation - Step: 14000 of 14646 - Loss: 0.06743581\n",
      "Epoch 16/20 time: 24.687964916229248s\n",
      "Epoch: 16 / 20, test_loss: 0.05984886735677719\n",
      "Epoch: 17 of 20\n",
      "Training - Step: 0 of 14646 - Loss: 0.052683927\n",
      "Training - Step: 1000 of 14646 - Loss: 0.05262786\n",
      "Training - Step: 2000 of 14646 - Loss: 0.046713993\n",
      "Training - Step: 3000 of 14646 - Loss: 0.044654064\n",
      "Training - Step: 4000 of 14646 - Loss: 0.05880966\n",
      "Training - Step: 5000 of 14646 - Loss: 0.07074654\n",
      "Training - Step: 6000 of 14646 - Loss: 0.061940994\n",
      "Training - Step: 7000 of 14646 - Loss: 0.050274454\n",
      "Training - Step: 8000 of 14646 - Loss: 0.059715413\n",
      "Training - Step: 9000 of 14646 - Loss: 0.0532238\n",
      "Training - Step: 10000 of 14646 - Loss: 0.076559156\n",
      "Training - Step: 11000 of 14646 - Loss: 0.040485047\n",
      "Training - Step: 12000 of 14646 - Loss: 0.050159972\n",
      "Training - Step: 13000 of 14646 - Loss: 0.06743567\n",
      "Training - Step: 14000 of 14646 - Loss: 0.057802554\n",
      "Epoch 17/20 time: 47.49241495132446s\n",
      "Validation - Step: 0 of 14646 - Loss: 0.07957934\n",
      "Validation - Step: 1000 of 14646 - Loss: 0.06377558\n",
      "Validation - Step: 2000 of 14646 - Loss: 0.067037106\n",
      "Validation - Step: 3000 of 14646 - Loss: 0.040748745\n",
      "Validation - Step: 4000 of 14646 - Loss: 0.055981405\n",
      "Validation - Step: 5000 of 14646 - Loss: 0.07479635\n",
      "Validation - Step: 6000 of 14646 - Loss: 0.060023062\n",
      "Validation - Step: 7000 of 14646 - Loss: 0.043296102\n",
      "Validation - Step: 8000 of 14646 - Loss: 0.056781735\n",
      "Validation - Step: 9000 of 14646 - Loss: 0.0708137\n",
      "Validation - Step: 10000 of 14646 - Loss: 0.06495901\n",
      "Validation - Step: 11000 of 14646 - Loss: 0.047482945\n",
      "Validation - Step: 12000 of 14646 - Loss: 0.06398325\n",
      "Validation - Step: 13000 of 14646 - Loss: 0.067064404\n",
      "Validation - Step: 14000 of 14646 - Loss: 0.065014616\n",
      "Epoch 17/20 time: 23.578192949295044s\n",
      "Epoch: 17 / 20, test_loss: 0.05976245179772377\n",
      "Epoch: 18 of 20\n",
      "Training - Step: 0 of 14646 - Loss: 0.05625976\n",
      "Training - Step: 1000 of 14646 - Loss: 0.040609173\n",
      "Training - Step: 2000 of 14646 - Loss: 0.054964155\n",
      "Training - Step: 3000 of 14646 - Loss: 0.06316061\n",
      "Training - Step: 4000 of 14646 - Loss: 0.057460997\n",
      "Training - Step: 5000 of 14646 - Loss: 0.045312062\n",
      "Training - Step: 6000 of 14646 - Loss: 0.06491426\n",
      "Training - Step: 7000 of 14646 - Loss: 0.051238794\n",
      "Training - Step: 8000 of 14646 - Loss: 0.05518447\n",
      "Training - Step: 9000 of 14646 - Loss: 0.062158592\n",
      "Training - Step: 10000 of 14646 - Loss: 0.0661106\n",
      "Training - Step: 11000 of 14646 - Loss: 0.06312817\n",
      "Training - Step: 12000 of 14646 - Loss: 0.050808642\n",
      "Training - Step: 13000 of 14646 - Loss: 0.07036853\n",
      "Training - Step: 14000 of 14646 - Loss: 0.040370815\n",
      "Epoch 18/20 time: 48.88422393798828s\n",
      "Validation - Step: 0 of 14646 - Loss: 0.06806729\n",
      "Validation - Step: 1000 of 14646 - Loss: 0.062055904\n",
      "Validation - Step: 2000 of 14646 - Loss: 0.05725407\n",
      "Validation - Step: 3000 of 14646 - Loss: 0.0708473\n",
      "Validation - Step: 4000 of 14646 - Loss: 0.07250164\n",
      "Validation - Step: 5000 of 14646 - Loss: 0.05836131\n",
      "Validation - Step: 6000 of 14646 - Loss: 0.0651636\n",
      "Validation - Step: 7000 of 14646 - Loss: 0.04938068\n",
      "Validation - Step: 8000 of 14646 - Loss: 0.08345494\n",
      "Validation - Step: 9000 of 14646 - Loss: 0.059875935\n",
      "Validation - Step: 10000 of 14646 - Loss: 0.087432906\n",
      "Validation - Step: 11000 of 14646 - Loss: 0.054007336\n",
      "Validation - Step: 12000 of 14646 - Loss: 0.058643322\n",
      "Validation - Step: 13000 of 14646 - Loss: 0.06808673\n",
      "Validation - Step: 14000 of 14646 - Loss: 0.07573885\n",
      "Epoch 18/20 time: 24.25306797027588s\n",
      "Epoch: 18 / 20, test_loss: 0.05871118605136871\n",
      "Epoch: 19 of 20\n",
      "Training - Step: 0 of 14646 - Loss: 0.065964885\n",
      "Training - Step: 1000 of 14646 - Loss: 0.046173096\n",
      "Training - Step: 2000 of 14646 - Loss: 0.044607982\n",
      "Training - Step: 3000 of 14646 - Loss: 0.051443465\n",
      "Training - Step: 4000 of 14646 - Loss: 0.061765224\n",
      "Training - Step: 5000 of 14646 - Loss: 0.06214469\n",
      "Training - Step: 6000 of 14646 - Loss: 0.04019233\n",
      "Training - Step: 7000 of 14646 - Loss: 0.06274411\n",
      "Training - Step: 8000 of 14646 - Loss: 0.059078455\n",
      "Training - Step: 9000 of 14646 - Loss: 0.058380395\n",
      "Training - Step: 10000 of 14646 - Loss: 0.054745227\n",
      "Training - Step: 11000 of 14646 - Loss: 0.07176678\n",
      "Training - Step: 12000 of 14646 - Loss: 0.07359629\n",
      "Training - Step: 13000 of 14646 - Loss: 0.065620854\n",
      "Training - Step: 14000 of 14646 - Loss: 0.061215296\n",
      "Epoch 19/20 time: 49.16476011276245s\n",
      "Validation - Step: 0 of 14646 - Loss: 0.07833459\n",
      "Validation - Step: 1000 of 14646 - Loss: 0.05263067\n",
      "Validation - Step: 2000 of 14646 - Loss: 0.06326899\n",
      "Validation - Step: 3000 of 14646 - Loss: 0.069328025\n",
      "Validation - Step: 4000 of 14646 - Loss: 0.052378386\n",
      "Validation - Step: 5000 of 14646 - Loss: 0.06461273\n",
      "Validation - Step: 6000 of 14646 - Loss: 0.062300704\n",
      "Validation - Step: 7000 of 14646 - Loss: 0.049532294\n",
      "Validation - Step: 8000 of 14646 - Loss: 0.053315625\n",
      "Validation - Step: 9000 of 14646 - Loss: 0.068633474\n",
      "Validation - Step: 10000 of 14646 - Loss: 0.07245601\n",
      "Validation - Step: 11000 of 14646 - Loss: 0.055109777\n",
      "Validation - Step: 12000 of 14646 - Loss: 0.048087627\n",
      "Validation - Step: 13000 of 14646 - Loss: 0.08416091\n",
      "Validation - Step: 14000 of 14646 - Loss: 0.056389347\n",
      "Epoch 19/20 time: 24.64387822151184s\n",
      "Epoch: 19 / 20, test_loss: 0.05845237523317337\n",
      "Saving training history to: ../data/jax_models/ddm//test_run_notebook_lan_ddm__jax_training_history.csv\n",
      "Saving model parameters to: ../data/jax_models/ddm//test_run_notebook_lan_ddm__train_state.jax\n",
      "Saving training config to: ../data/jax_models/ddm//test_run_notebook_lan_ddm__train_config.pickle\n",
      "Saving training data details to: ../data/jax_models/ddm//test_run_notebook_lan_ddm__data_details.pickle\n"
     ]
    }
   ],
   "source": [
    "train_state = jax_trainer.train_and_evaluate(\n",
    "    output_folder=\"../data/jax_models/\" + MODEL + \"/\",\n",
    "    output_file_id=MODEL,\n",
    "    run_id=\"test_run_notebook\",\n",
    "    wandb_on=False,\n",
    "    wandb_project_id=\"test_run_notebook\",\n",
    "    save_data_details=True,\n",
    "    verbose=1,\n",
    "    save_all=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loaded Net\n",
    "jax_infer = lanfactory.trainers.JaxMLPFactory(\n",
    "    # network_config=\"../data/jax_models/\"\n",
    "    # + MODEL\n",
    "    # + \"/\"\n",
    "    # + \"test_run_notebook\"\n",
    "    # + \"_lan_ddm__network_config.pickle\",\n",
    "    network_config=network_config,\n",
    "    train=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "state argument has to be a dictionary or a string!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m forward_pass \u001b[38;5;241m=\u001b[39m \u001b[43mjax_infer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_forward_partial\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/lanfactory/lib/python3.11/site-packages/flax/linen/module.py:699\u001b[0m, in \u001b[0;36mwrap_method_once.<locals>.wrapped_module_method\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    697\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(args[\u001b[38;5;241m0\u001b[39m], Module):\n\u001b[1;32m    698\u001b[0m   \u001b[38;5;28mself\u001b[39m, args \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m], args[\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m--> 699\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_wrapped_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    700\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    701\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fun(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/lanfactory/lib/python3.11/site-packages/flax/linen/module.py:1216\u001b[0m, in \u001b[0;36mModule._call_wrapped_method\u001b[0;34m(self, fun, args, kwargs)\u001b[0m\n\u001b[1;32m   1214\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _use_named_call:\n\u001b[1;32m   1215\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m jax\u001b[38;5;241m.\u001b[39mnamed_scope(_derive_profiling_name(\u001b[38;5;28mself\u001b[39m, fun)):\n\u001b[0;32m-> 1216\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mrun_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1217\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1218\u001b[0m   y \u001b[38;5;241m=\u001b[39m run_fun(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-Personal/project_lanfactory/LANfactory/lanfactory/trainers/jax_mlp.py:221\u001b[0m, in \u001b[0;36mJaxMLP.make_forward_partial\u001b[0;34m(self, seed, input_dim, state, add_jitted)\u001b[0m\n\u001b[1;32m    219\u001b[0m     loaded_state \u001b[38;5;241m=\u001b[39m state\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 221\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstate argument has to be a dictionary or a string!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    223\u001b[0m \u001b[38;5;66;03m# Make forward pass\u001b[39;00m\n\u001b[1;32m    224\u001b[0m net_forward \u001b[38;5;241m=\u001b[39m partial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply, loaded_state)\n",
      "\u001b[0;31mValueError\u001b[0m: state argument has to be a dictionary or a string!"
     ]
    }
   ],
   "source": [
    "forward_pass = jax_infer.make_forward_partial()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passing through identity\n"
     ]
    }
   ],
   "source": [
    "forward_pass, forward_pass_jitted = jax_infer.make_forward_partial(\n",
    "    seed=42,\n",
    "    input_dim=model_config[\"n_params\"] + 2,\n",
    "    state=\"../data/jax_models/\" + MODEL + \"/test_run_notebook_lan_ddm__train_state.jax\",\n",
    "    add_jitted=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passing through identity\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10, 1)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "forward_pass(np.ones((10, 6))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "\n",
    "# Test parameters:\n",
    "theta = deepcopy(ssms.config.model_config[MODEL][\"default_params\"])\n",
    "\n",
    "theta[0] = 0.2\n",
    "theta[3] = 1.0\n",
    "\n",
    "# Comparison simulator run\n",
    "sim_out = ssms.basic_simulators.simulator.simulator(\n",
    "    model=MODEL, theta=theta, n_samples=50000\n",
    ")\n",
    "\n",
    "# Make input metric\n",
    "input_mat = jnp.zeros((2000, len(theta) + 2))\n",
    "for i in range(len(theta)):\n",
    "    input_mat = input_mat.at[:, i].set(jnp.ones(2000) * theta[i])\n",
    "\n",
    "input_mat = input_mat.at[:, len(theta)].set(\n",
    "    jnp.array(\n",
    "        np.concatenate(\n",
    "            [\n",
    "                np.linspace(5, 0, 1000).astype(np.float32),\n",
    "                np.linspace(0, 5, 1000).astype(np.float32),\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    ")\n",
    "input_mat = input_mat.at[:, len(theta) + 1].set(\n",
    "    jnp.array(\n",
    "        np.concatenate([np.repeat(-1.0, 1000), np.repeat(1.0, 1000)]).astype(np.float32)\n",
    "    )\n",
    ")\n",
    "\n",
    "net_out = forward_pass_jitted(input_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.07477757e-04, 2.14955515e-04, 1.07477757e-04, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 6.44866544e-04, 4.29911029e-04,\n",
       "        6.44866544e-04, 6.44866544e-04, 6.44866544e-04, 8.59822058e-04,\n",
       "        9.67299815e-04, 1.50468860e-03, 1.50468860e-03, 2.25703290e-03,\n",
       "        3.22433272e-03, 2.57946617e-03, 4.83649908e-03, 4.62154356e-03,\n",
       "        8.16830955e-03, 8.16830955e-03, 9.99543142e-03, 1.33272419e-02,\n",
       "        1.79487855e-02, 2.28927623e-02, 2.90189945e-02, 3.49302711e-02,\n",
       "        4.37434472e-02, 5.45987007e-02, 7.39446970e-02, 8.72719389e-02,\n",
       "        1.13711467e-01, 1.40903340e-01, 1.71104590e-01, 2.14418126e-01,\n",
       "        2.61385906e-01, 3.31676359e-01, 3.45433512e-01, 1.28328442e-01,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.53048326e-01,\n",
       "        5.10089436e-01, 4.96224805e-01, 4.30878329e-01, 3.27914637e-01,\n",
       "        2.55474629e-01, 2.17642458e-01, 1.68095212e-01, 1.35314496e-01,\n",
       "        1.04790813e-01, 8.72719389e-02, 7.44820858e-02, 5.43837452e-02,\n",
       "        4.32060584e-02, 3.58975709e-02, 2.92339500e-02, 2.40750176e-02,\n",
       "        1.74113967e-02, 1.27898531e-02, 1.21449866e-02, 9.78047591e-03,\n",
       "        7.41596525e-03, 4.94397683e-03, 5.37388786e-03, 3.76172150e-03,\n",
       "        2.90189945e-03, 3.22433272e-03, 1.07477757e-03, 2.04207739e-03,\n",
       "        1.61216636e-03, 6.44866544e-04, 7.52344301e-04, 5.37388786e-04,\n",
       "        6.44866544e-04, 3.22433272e-04, 1.07477757e-04, 3.22433272e-04,\n",
       "        2.14955515e-04, 2.14955515e-04, 5.37388786e-04, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 2.14955515e-04,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.07477757e-04]),\n",
       " array([-8.47512817, -8.28904316, -8.10295815, -7.91687313, -7.73078812,\n",
       "        -7.5447031 , -7.35861809, -7.17253307, -6.98644806, -6.80036304,\n",
       "        -6.61427803, -6.42819302, -6.242108  , -6.05602299, -5.86993797,\n",
       "        -5.68385296, -5.49776794, -5.31168293, -5.12559792, -4.9395129 ,\n",
       "        -4.75342789, -4.56734287, -4.38125786, -4.19517284, -4.00908783,\n",
       "        -3.82300282, -3.6369178 , -3.45083279, -3.26474777, -3.07866276,\n",
       "        -2.89257774, -2.70649273, -2.52040771, -2.3343227 , -2.14823769,\n",
       "        -1.96215267, -1.77606766, -1.58998264, -1.40389763, -1.21781261,\n",
       "        -1.0317276 , -0.84564259, -0.65955757, -0.47347256, -0.28738754,\n",
       "        -0.10130253,  0.08478249,  0.2708675 ,  0.45695251,  0.64303753,\n",
       "         0.82912254,  1.01520756,  1.20129257,  1.38737759,  1.5734626 ,\n",
       "         1.75954762,  1.94563263,  2.13171764,  2.31780266,  2.50388767,\n",
       "         2.68997269,  2.8760577 ,  3.06214272,  3.24822773,  3.43431274,\n",
       "         3.62039776,  3.80648277,  3.99256779,  4.1786528 ,  4.36473782,\n",
       "         4.55082283,  4.73690784,  4.92299286,  5.10907787,  5.29516289,\n",
       "         5.4812479 ,  5.66733292,  5.85341793,  6.03950294,  6.22558796,\n",
       "         6.41167297,  6.59775799,  6.783843  ,  6.96992802,  7.15601303,\n",
       "         7.34209805,  7.52818306,  7.71426807,  7.90035309,  8.0864381 ,\n",
       "         8.27252312,  8.45860813,  8.64469315,  8.83077816,  9.01686317,\n",
       "         9.20294819,  9.3890332 ,  9.57511822,  9.76120323,  9.94728825,\n",
       "        10.13337326]),\n",
       " [<matplotlib.patches.Polygon at 0x2d44fff40>])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.plot(np.linspace(-5, 5, 2000).astype(np.float32), np.exp(net_out))\n",
    "\n",
    "plt.hist(\n",
    "    sim_out[\"rts\"] * sim_out[\"choices\"],\n",
    "    bins=100,\n",
    "    histtype=\"step\",\n",
    "    fill=None,\n",
    "    density=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ssms_dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
